{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing modules that are needed\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as f \n",
    "import torch.optim as optim \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Loading the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f = pd.read_csv(\\\n",
    "    '~/ml_J1-J2_supervised/all_phase/af/augumented_dataL24.csv',index_col=[0])\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(data_f.iloc[:,:-1],data_f.iloc[:,-1:], \\\n",
    "                    random_state=42,test_size=0.2,stratify=data_f.iloc[:,-1:])\n",
    "\n",
    "data_train = pd.concat([X_train,y_train],axis=1)\n",
    "data_test = pd.concat([X_test,y_test],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the device**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Class definition that is used to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### class to load the data\n",
    "\n",
    "class LoadData(Dataset):\n",
    "    def __init__(self,data,L,device=device):\n",
    "        self.L = L\n",
    "        self.x_data = torch.tensor(data.iloc[:,:-1].values,dtype=torch.float32).to(device=device)\n",
    "        self.y_data = torch.tensor(data.iloc[:,-1:].values,dtype=torch.long).to(device=device)\n",
    "\n",
    "    ### length of the dataset\n",
    "    ### function one has to use if you want to define a custom dataset class\n",
    "    def __len__(self):\n",
    "        return len(self.y_data)\n",
    "\n",
    "    \n",
    "    ## get the image and label\n",
    "    def __getitem__(self,idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.to_list()\n",
    "        \n",
    "        image = self.x_data[idx,:]\n",
    "        label = self.y_data[idx]\n",
    "\n",
    "        return {'data':image,'label':label}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Model definition for the variational autoencoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "### definition of the network\n",
    "class encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size,latent_dim):\n",
    "        super(encoder,self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.input_size = input_size\n",
    "        ### encoder network\n",
    "        self.encoder1 = nn.Linear(in_features=self.input_size,out_features=256)\n",
    "        self.encoder2 = nn.Linear(in_features=256,out_features=128)\n",
    "        self.encoder3 = nn.Linear(in_features=128,out_features=64)\n",
    "        self.encoder4 = nn.Linear(in_features=64,out_features=32)\n",
    "\n",
    "        self.mu = nn.Linear(in_features=32,out_features=self.latent_dim)\n",
    "        self.var = nn.Linear(in_features=32,out_features=self.latent_dim)\n",
    "\n",
    "    ### feedforward network \n",
    "    def forward(self,x):\n",
    "        ##  passing the input through the network\n",
    "        x = self.encoder1(x)\n",
    "        x = self.encoder2(x)\n",
    "        x = self.encoder3(x)\n",
    "        x = self.encoder4(x)\n",
    "\n",
    "        ## passing input x to layer mu and var, mux = g(x), sigmax = f(x) \n",
    "        x1 = self.mu(x)\n",
    "        x2 = self.var(x)\n",
    "\n",
    "        ## combining mu and sigma to a normal distribution reparameterization trick\n",
    "        ##  z = mu + sigma * N(0,1)\n",
    "        #zi = torch.distributions.Normal(0,1).rsample([self.latent_dim])\n",
    "        #x = x1 + x2*zi\n",
    "\n",
    "        return x,x1,x2\n",
    "\n",
    "\n",
    "\n",
    "### definition of the network\n",
    "class decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, latent_dim):\n",
    "        super(decoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.input_size = input_size\n",
    "       \n",
    "        ### decoder network\n",
    "        self.decoder1 = nn.Linear(in_features=self.latent_dim, out_features=32)\n",
    "        self.decoder2 = nn.Linear(in_features=32, out_features=64)\n",
    "        self.decoder3 = nn.Linear(in_features=64, out_features=128)\n",
    "        self.decoder4 = nn.Linear(in_features=128, out_features=self.input_size)\n",
    "\n",
    "    ### feedforward network\n",
    "    def forward(self, x):\n",
    "        ##  passing the input through the network\n",
    "       \n",
    "        x = self.decoder1(x)\n",
    "        x = self.decoder2(x)\n",
    "        x = self.decoder3(x)\n",
    "        x = self.decoder4(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps of the process\n",
    "* Pass the input $X$ through the encoder stage $x_enc$\n",
    "* To get estimate of $\\mu$ and $\\sigma$ use two neural network and pass $x_enc$ through both of them\n",
    "    * $\\mu_{x} = f_{2}(f_{1}(x))$\n",
    "    * $\\sigma_{x} = g_{2}(f_{1}(x))$\n",
    "    * Network $f_{1}(x)$ represents the input that is passed through various stages (neural network) and $f_{2},g_{2}$ represents two different neural network.\n",
    "* To generate the distribution $q(z|x)$ use $\\mu_{x},\\sigma_{x}$ to generate a normal distribution.\n",
    "    * $q(z|x) = \\mathcal{N}(\\mu_{x},\\sigma_{x})$\n",
    "    * Sample a point from this distribution $q(z|x)$\n",
    "* Now using $z$ we have to generate $p(x|z)$.\n",
    "* The error one is trying to minimize is \n",
    "\\begin{equation}\n",
    "min E_{q} \\left [ \\log q(z|x) - \\log p(z) \\right ] -  {E}_{q} \\log p(x|z) \n",
    "\\end{equation}\n",
    "* Here $E_{q}$ means average value for a given distribution of $q(z|x)$\n",
    "* Distribution $p(z) = \\mathcal{N} (0,1)$ is a standard normal.\n",
    "* Distribution $p(x|z) = \\mathcal{N}(f(z),cI) = \\mathcal{N} (decoder(z),cI)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.5051e-02, -5.5179e-05,  1.8747e-01,  8.6430e-02, -3.6078e-02,\n",
      "         8.7773e-02,  6.3990e-02, -4.3571e-02,  3.2093e-02, -9.9308e-02,\n",
      "        -1.3944e-01,  2.8436e-01,  7.1158e-02, -1.3529e-01, -1.4323e-01,\n",
      "        -2.4819e-01, -1.6410e-01,  1.1253e-01,  3.3471e-02, -2.1864e-01,\n",
      "        -1.2842e-01, -1.4076e-01,  7.2643e-02,  5.4157e-02,  6.4891e-02,\n",
      "         3.2861e-01, -6.6576e-02, -1.6196e-01,  1.7775e-01, -2.3813e-02,\n",
      "        -3.5401e-01, -2.0571e-01], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0509, -0.0699, -0.0345,  0.1407,  0.0108, -0.2321,  0.0914, -0.2044,\n",
      "        -0.0070,  0.0246, -0.0931,  0.0832, -0.0717,  0.0971,  0.2505, -0.0178,\n",
      "         0.0095,  0.1251, -0.0062,  0.0823, -0.0024, -0.2768,  0.0653,  0.2125,\n",
      "        -0.2291, -0.1535,  0.0096,  0.1226, -0.0060, -0.1472, -0.0033, -0.0599],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0309,  0.0352,  0.1227, -0.0903, -0.0117,  0.0471, -0.1803,  0.0660,\n",
      "         0.0904, -0.2177,  0.1588, -0.1339,  0.2165,  0.1844,  0.0851, -0.0151,\n",
      "         0.0564, -0.2943, -0.1402, -0.1463,  0.0775,  0.0580, -0.1838, -0.0427,\n",
      "         0.2084,  0.0569,  0.0640, -0.1612, -0.3064, -0.1786,  0.2529,  0.1246],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_size = 576\n",
    "latent_dim = 32\n",
    "x = torch.randn(input_size)\n",
    "\n",
    "### create an instance of encoder network\n",
    "encdr = encoder(input_size,latent_dim)\n",
    "\n",
    "## generate encoded output and mu,sigma values\n",
    "enc,mu,sigma = encdr(x)\n",
    "\n",
    "## create an instance of decoder network\n",
    "decdr = decoder(input_size,latent_dim)\n",
    "\n",
    "## generate distribution\n",
    "q  = torch.distributions.Normal(mu,sigma).rsample()\n",
    "x_new = decdr(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones_like(xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = torch.rand([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "exp(): argument 'input' (position 1) must be Tensor, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-220113cf6849>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: exp(): argument 'input' (position 1) must be Tensor, not float"
     ]
    }
   ],
   "source": [
    "torch.exp(1./2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.], requires_grad=True) tensor([1.], grad_fn=<ExpBackward>)\n"
     ]
    }
   ],
   "source": [
    "yi = torch.nn.Parameter(torch.Tensor([0.0]))\n",
    "scale = torch.exp(yi)\n",
    "print(yi,scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "142c5f550c5dca9f67c8c920311c6ac8b8cbcb1ffb5f20302b2d142b28b10006"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 ('python38-demo-v2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
