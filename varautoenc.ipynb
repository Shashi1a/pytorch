{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing modules that are needed\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as f \n",
    "import torch.optim as optim \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Loading the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/shashi/ml_J1-J2_supervised/all_phase/af/augumented_dataL24.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8dfa951173ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m data_f = pd.read_csv(\\\n\u001b[0m\u001b[1;32m      2\u001b[0m     '~/ml_J1-J2_supervised/all_phase/af/augumented_dataL24.csv',index_col=[0])\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m X_train,X_test,y_train,y_test = train_test_split(data_f.iloc[:,:-1],data_f.iloc[:,-1:], \\\n\u001b[1;32m      5\u001b[0m                     random_state=42,test_size=0.2,stratify=data_f.iloc[:,-1:])\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_env/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/shashi/ml_J1-J2_supervised/all_phase/af/augumented_dataL24.csv'"
     ]
    }
   ],
   "source": [
    "data_f = pd.read_csv(\\\n",
    "    '~/ml_J1-J2_supervised/all_phase/af/augumented_dataL24.csv',index_col=[0])\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(data_f.iloc[:,:-1],data_f.iloc[:,-1:], \\\n",
    "                    random_state=42,test_size=0.2,stratify=data_f.iloc[:,-1:])\n",
    "\n",
    "data_train = pd.concat([X_train,y_train],axis=1)\n",
    "data_test = pd.concat([X_test,y_test],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the device**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Class definition that is used to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### class to load the data\n",
    "\n",
    "class LoadData(Dataset):\n",
    "    def __init__(self,data,L,device=device):\n",
    "        self.L = L\n",
    "        self.x_data = torch.tensor(data.iloc[:,:-1].values,dtype=torch.float32).to(device=device)\n",
    "        self.y_data = torch.tensor(data.iloc[:,-1:].values,dtype=torch.long).to(device=device)\n",
    "\n",
    "    ### length of the dataset\n",
    "    ### function one has to use if you want to define a custom dataset class\n",
    "    def __len__(self):\n",
    "        return len(self.y_data)\n",
    "\n",
    "    \n",
    "    ## get the image and label\n",
    "    def __getitem__(self,idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.to_list()\n",
    "        \n",
    "        image = self.x_data[idx,:]\n",
    "        label = self.y_data[idx]\n",
    "\n",
    "        return {'data':image,'label':label}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Model definition for the variational autoencoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### definition of the network\n",
    "class encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size,latent_dim):\n",
    "        super(encoder,self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.input_size = input_size\n",
    "        ### encoder network\n",
    "        self.encoder1 = nn.Linear(in_features=self.input_size,out_features=256)\n",
    "        self.encoder2 = nn.Linear(in_features=256,out_features=128)\n",
    "        self.encoder3 = nn.Linear(in_features=128,out_features=64)\n",
    "        self.encoder4 = nn.Linear(in_features=64,out_features=32)\n",
    "\n",
    "        self.mu = nn.Linear(in_features=32,out_features=self.latent_dim)\n",
    "        self.var = nn.Linear(in_features=32,out_features=self.latent_dim)\n",
    "\n",
    "    ### feedforward network \n",
    "    def forward(self,x):\n",
    "        ##  passing the input through the network\n",
    "        x = self.encoder1(x)\n",
    "        x = self.encoder2(x)\n",
    "        x = self.encoder3(x)\n",
    "        x = self.encoder4(x)\n",
    "\n",
    "        ## passing input x to layer mu and var, mux = g(x), sigmax = f(x) \n",
    "        x1 = self.mu(x)\n",
    "        x2 = self.var(x)\n",
    "\n",
    "        ## combining mu and sigma to a normal distribution reparameterization trick\n",
    "        ##  z = mu + sigma * N(0,1)\n",
    "        #zi = torch.distributions.Normal(0,1).rsample([self.latent_dim])\n",
    "        #x = x1 + x2*zi\n",
    "\n",
    "        return x,x1,x2\n",
    "\n",
    "\n",
    "\n",
    "### definition of the network\n",
    "class decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, latent_dim):\n",
    "        super(decoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.input_size = input_size\n",
    "       \n",
    "        ### decoder network\n",
    "        self.decoder1 = nn.Linear(in_features=self.latent_dim, out_features=32)\n",
    "        self.decoder2 = nn.Linear(in_features=32, out_features=64)\n",
    "        self.decoder3 = nn.Linear(in_features=64, out_features=128)\n",
    "        self.decoder4 = nn.Linear(in_features=128, out_features=self.input_size)\n",
    "\n",
    "    ### feedforward network\n",
    "    def forward(self, x):\n",
    "        ##  passing the input through the network\n",
    "       \n",
    "        x = self.decoder1(x)\n",
    "        x = self.decoder2(x)\n",
    "        x = self.decoder3(x)\n",
    "        x = self.decoder4(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps of the process\n",
    "* Pass the input $X$ through the encoder stage $x_enc$\n",
    "* To get estimate of $\\mu$ and $\\sigma$ use two neural network and pass $x_enc$ through both of them\n",
    "    * $\\mu_{x} = f_{2}(f_{1}(x))$\n",
    "    * $\\sigma_{x} = g_{2}(f_{1}(x))$\n",
    "    * $\\mu_{x},\\sigma_{x}$ are vectors of dimension $d_{enc}$(encoding dimension)\n",
    "    * Network $f_{1}(x)$ represents the input that is passed through various stages (neural network) and $f_{2},g_{2}$ represents two different neural network.\n",
    "* To generate the distribution $q(z|x)$ use $\\mu_{x},\\sigma_{x}$ to generate a normal distribution.\n",
    "    * $q(z|x)$ is a multidimensional distribution with means given by $\\mu_{x}$ vector and variance given by $\\sigma_{x}$ vector. \n",
    "    * $q(z|x) = \\mathcal{N}(\\mu_{x},\\sigma_{x})$\n",
    "    * Sample a point from this distribution $q(z|x)$\n",
    "* Now using $z$ we have to generate $p(x|z)$.\n",
    "* The error one is trying to minimize is \n",
    "\\begin{equation}\n",
    "min E_{q} \\left [ \\log q(z|x) - \\log p(z) \\right ] -  {E}_{q} \\log p(x|z) \n",
    "\\end{equation}\n",
    "* Here $E_{q}$ means average value for a given distribution of $q(z|x)$\n",
    "* Distribution $p(z) = \\mathcal{N} (0,1)$ is a standard normal.\n",
    "* Distribution $p(x|z) = \\mathcal{N}(f(z),cI) = \\mathcal{N} (decoder(z),cI)$ \n",
    "\n",
    "* $x --[encoder]-->x_{enc},\\mu_{x},\\sigma_{x} -->\\mathcal{N}(\\mu_{x},\\sigma_{x})--> [decoder]--->x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Steps for the computation**\n",
    "1. I will use the vector notation where the data $\\vec{x}$ is cosidered as a vector.\n",
    "1. Instantiate encoder object\n",
    "1. The data $\\vec{x}$ passed through the encoder network will give us $\\vec{\\mu}_{x}, \\vec{\\sigma}_{x}$.\n",
    "1. $\\vec{x}$ is the vector in the space of the data and $\\vec{\\mu}_{x},\\vec{\\sigma}_{x}$ vector in the latent/encoding dimension.\n",
    "1. The distribution $\\bold{q}(z|x)$ is obtained from $\\vec{\\mu}_{x}$ and $\\vec{\\sigma}_{x}$.\n",
    "    * $\\bold{q}(z|x) \\equiv \\mathcal{N}(\\vec{\\mu}_{x},\\vec{\\sigma}_{x})$\n",
    "    * $\\vec{z}$ is sampled from the distribution $\\bold{q}(z|x)$\n",
    "1. $\\vec{z}$ is passed through the decoder network to give $\\hat{x}$\n",
    "1. We need to compute $\\bold{p}(\\hat{x}|z)$.\n",
    "    * This distribution is $\\bold{p}(\\hat{x}|z) \\equiv \\mathcal{N}(f(z),cI)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0401,  0.1875, -0.0988,  0.2141, -0.1828,  0.2008, -0.0694,  0.1027,\n",
      "        -0.1705,  0.1471,  0.1004,  0.2217, -0.0063, -0.0665, -0.0971, -0.3043,\n",
      "        -0.1484, -0.1096, -0.0980,  0.0626,  0.0152,  0.1768,  0.0393, -0.1000,\n",
      "        -0.0330, -0.1884, -0.0192, -0.1777,  0.0384,  0.1635, -0.1496, -0.1226],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter scale (Tensor of shape (32,)) of distribution Normal(loc: torch.Size([32]), scale: torch.Size([32])) to satisfy the constraint GreaterThan(lower_bound=0.0), but found invalid values:\ntensor([-0.0888, -0.1067,  0.1868, -0.0179, -0.0805, -0.0762, -0.0806,  0.0584,\n        -0.1148,  0.1615, -0.1582, -0.1890,  0.0938, -0.1230,  0.1164, -0.0443,\n        -0.0380,  0.2295,  0.0536,  0.0275, -0.0710,  0.1306,  0.1789,  0.0417,\n        -0.0263,  0.2756,  0.1133, -0.0234, -0.0112, -0.1482, -0.0625,  0.0670])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-47128debff53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m## generate multidimensional distribution q(z|x) using mu(x) and sigma(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m## z is passed as an input to the decoder object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mq_zx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m## prior distribution of z p(z) = N(0,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_env/lib/python3.8/site-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_env/lib/python3.8/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m     56\u001b[0m                         \u001b[0;34mf\"Expected parameter {param} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                         \u001b[0;34mf\"({type(value).__name__} of shape {tuple(value.shape)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected parameter scale (Tensor of shape (32,)) of distribution Normal(loc: torch.Size([32]), scale: torch.Size([32])) to satisfy the constraint GreaterThan(lower_bound=0.0), but found invalid values:\ntensor([-0.0888, -0.1067,  0.1868, -0.0179, -0.0805, -0.0762, -0.0806,  0.0584,\n        -0.1148,  0.1615, -0.1582, -0.1890,  0.0938, -0.1230,  0.1164, -0.0443,\n        -0.0380,  0.2295,  0.0536,  0.0275, -0.0710,  0.1306,  0.1789,  0.0417,\n        -0.0263,  0.2756,  0.1133, -0.0234, -0.0112, -0.1482, -0.0625,  0.0670])"
     ]
    }
   ],
   "source": [
    "input_size = 32\n",
    "latent_dim = 32\n",
    "x = torch.randn(input_size)\n",
    "\n",
    "### create an instance of encoder network\n",
    "encdr = encoder(input_size,latent_dim)\n",
    "\n",
    "## generate encoded output and mu,sigma values\n",
    "x_enc,mu,sigma = encdr(x)\n",
    "\n",
    "## create an instance of decoder network\n",
    "decdr = decoder(input_size,latent_dim)\n",
    "## generate multidimensional distribution q(z|x) using mu(x) and sigma(x) \n",
    "## z is passed as an input to the decoder object\n",
    "q_zx  = torch.distributions.Normal(mu.data,sigma.data)\n",
    "\n",
    "## prior distribution of z p(z) = N(0,1)\n",
    "## will be used to calculate the KL divergence\n",
    "\n",
    "#p_z = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(sigma))\n",
    "\n",
    "## sampling z from the q_zx\n",
    "\n",
    "#z = q_zx.rsample()\n",
    "\n",
    "## measuring the log probability of z being in q(z|x) and p(z)\n",
    "\n",
    "#log_qzx = q_zx.log_prob(z)\n",
    "#log_pz = p_z.log_prob(z)\n",
    "\n",
    "\n",
    "### passing z to decoder network to get xnew \n",
    "\n",
    "#x_new = decdr(z)\n",
    "\n",
    "### generate distribution p(x|z) \n",
    "#p_xz = torch.distributions.Normal(x_new,torch.ones_like(x_new))\n",
    "\n",
    "### measure log p(x|z) \n",
    "#log_pxz = p_xz.log(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = torch.rand([10])\n",
    "p_xz = torch.distributions.Normal(xi,xi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0690, -0.0463, -0.0693,  0.0466,  0.1630, -0.1311,  0.1725, -0.0606,\n",
       "         0.0797, -0.1888, -0.1515, -0.0336,  0.1242,  0.0949,  0.1362, -0.0273,\n",
       "        -0.0293, -0.1463,  0.0584, -0.0516,  0.0967,  0.2002,  0.1508,  0.0385,\n",
       "         0.0708, -0.0302, -0.0302, -0.1748, -0.0062, -0.1858, -0.2742,  0.0707])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "tensor.H is only supported on matrices (2-D tensors). Got 1-D tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-579a75dc0c9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: tensor.H is only supported on matrices (2-D tensors). Got 1-D tensor."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "142c5f550c5dca9f67c8c920311c6ac8b8cbcb1ffb5f20302b2d142b28b10006"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 ('python38-demo-v2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
